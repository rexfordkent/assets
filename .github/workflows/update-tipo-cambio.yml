name: Actualizar Tipo de Cambio

on:
  schedule:
    - cron: '0 * * * *'
  workflow_dispatch:
  push:
    branches: [ main ]

permissions:
  contents: write

jobs:
  update-rates:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        pip install requests beautifulsoup4 selenium webdriver-manager
    
    - name: Scraping REAL sin hardcodeo
      run: |
        cat > scraper.py << 'ENDOFSCRIPT'
        import requests
        from bs4 import BeautifulSoup
        import json
        import re
        from datetime import datetime
        import urllib3
        urllib3.disable_warnings()
        
        def get_sunat():
            try:
                print("Intentando obtener SUNAT...")
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                    'Accept-Language': 'es-PE,es;q=0.9',
                    'Connection': 'keep-alive',
                    'Referer': 'https://www.sunat.gob.pe/'
                }
                
                session = requests.Session()
                response = session.get(
                    'https://e-consulta.sunat.gob.pe/cl-at-ittipcam/tcS01Alias',
                    headers=headers,
                    verify=False,
                    timeout=30,
                    allow_redirects=True
                )
                
                print(f"SUNAT Status: {response.status_code}")
                print(f"SUNAT Content Length: {len(response.text)}")
                
                if response.status_code == 200 and len(response.text) > 1000:
                    html = response.text
                    
                    # Buscar TODOS los valores numericos que parezcan tipo de cambio
                    pattern = r'3\.\d{3}'
                    all_values = re.findall(pattern, html)
                    
                    if all_values:
                        print(f"Valores encontrados en SUNAT: {all_values[:10]}")
                        
                        # Filtrar valores validos
                        valid_values = []
                        for val in all_values:
                            num = float(val)
                            if 3.4 <= num <= 3.8:
                                valid_values.append(num)
                        
                        if len(valid_values) >= 2:
                            # Tomar los primeros dos valores unicos
                            unique_values = list(dict.fromkeys(valid_values))
                            
                            if len(unique_values) >= 2:
                                compra = min(unique_values[0], unique_values[1])
                                venta = max(unique_values[0], unique_values[1])
                            else:
                                compra = venta = unique_values[0]
                            
                            print(f"SUNAT REAL: Compra={compra}, Venta={venta}")
                            
                            return {
                                "compra": compra,
                                "venta": venta,
                                "fecha": datetime.now().strftime("%d/%m/%Y"),
                                "fuente": "web_scraping"
                            }
                        elif len(valid_values) == 1:
                            val = valid_values[0]
                            print(f"SUNAT un solo valor: {val}")
                            return {
                                "compra": val,
                                "venta": val,
                                "fecha": datetime.now().strftime("%d/%m/%Y"),
                                "fuente": "web_scraping"
                            }
                    
                    print("No se encontraron valores validos en SUNAT")
                else:
                    print(f"Error: respuesta invalida de SUNAT")
                    
            except Exception as e:
                print(f"Error SUNAT: {e}")
                import traceback
                traceback.print_exc()
            
            # NO HARDCODEAR - devolver error si no se puede obtener
            return {"error": True, "message": "No se pudo obtener de SUNAT"}
        
        def get_sbs():
            try:
                print("Intentando obtener SBS...")
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
                }
                
                response = requests.get(
                    'https://www.sbs.gob.pe/app/pp/sistip_portal/paginas/publicacion/tipocambiopromedio.aspx',
                    headers=headers,
                    verify=False,
                    timeout=30
                )
                
                print(f"SBS Status: {response.status_code}")
                
                if response.status_code == 200:
                    html = response.text
                    soup = BeautifulSoup(html, 'html.parser')
                    
                    # Buscar tabla con Dolar
                    tables = soup.find_all('table')
                    
                    for table in tables:
                        text = table.get_text()
                        if 'lar de N.A.' in text or 'Dolar' in text or 'DOLAR' in text:
                            # Extraer todos los numeros de la tabla
                            numeros = re.findall(r'3\.\d{3}', text)
                            
                            if numeros:
                                print(f"SBS numeros encontrados: {numeros}")
                                
                                valores = [float(n) for n in numeros if 3.4 <= float(n) <= 3.8]
                                
                                if len(valores) >= 2:
                                    compra = valores[0]
                                    venta = valores[1]
                                    
                                    print(f"SBS REAL: Compra={compra}, Venta={venta}")
                                    
                                    return {
                                        "compra": compra,
                                        "venta": venta,
                                        "fecha": datetime.now().strftime("%d/%m/%Y"),
                                        "fuente": "web_scraping"
                                    }
                                elif len(valores) == 1:
                                    val = valores[0]
                                    print(f"SBS un valor: {val}")
                                    return {
                                        "compra": val,
                                        "venta": val,
                                        "fecha": datetime.now().strftime("%d/%m/%Y"),
                                        "fuente": "web_scraping"
                                    }
                    
                    # Si no encuentra en tablas, buscar en todo el HTML
                    all_values = re.findall(r'3\.\d{3}', html)
                    if all_values:
                        valores = [float(n) for n in all_values if 3.4 <= float(n) <= 3.8]
                        valores = list(dict.fromkeys(valores))  # Unicos
                        
                        if len(valores) >= 2:
                            print(f"SBS valores del HTML: {valores[0]}/{valores[1]}")
                            return {
                                "compra": valores[0],
                                "venta": valores[1],
                                "fecha": datetime.now().strftime("%d/%m/%Y"),
                                "fuente": "web_scraping"
                            }
                    
                    print("SBS: No se encontraron valores")
                    
            except Exception as e:
                print(f"Error SBS: {e}")
                import traceback
                traceback.print_exc()
            
            # NO HARDCODEAR - devolver error si no se puede obtener
            return {"error": True, "message": "No se pudo obtener de SBS"}
        
        print("=" * 60)
        print("SCRAPING SIN VALORES HARDCODEADOS")
        print("=" * 60)
        
        sunat_data = get_sunat()
        sbs_data = get_sbs()
        
        # NO HARDCODEAR NADA - si falla, que muestre error
        
        result = {
            "sunat": sunat_data,
            "sbs": sbs_data,
            "ultima_actualizacion": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        # Guardar JSON
        with open('tipo-cambio.json', 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        
        print("\n" + "=" * 60)
        print("RESULTADO FINAL SIN HARDCODEO:")
        print(f"SUNAT: {sunat_data}")
        print(f"SBS: {sbs_data}")
        print("=" * 60)
        
        # Verificar si al menos uno tiene datos
        if sunat_data.get('error') and sbs_data.get('error'):
            print("WARNING: Ninguna fuente pudo ser obtenida")
        else:
            print("OK: Al menos una fuente fue obtenida")
        ENDOFSCRIPT
        
        python scraper.py
    
    - name: Mostrar JSON final
      run: |
        echo "===== JSON FINAL ====="
        cat tipo-cambio.json
    
    - name: Commit y Push
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add tipo-cambio.json
        git commit -m "TC Real sin hardcodeo - $(date +'%d/%m/%Y %H:%M')" || echo "No changes"
        git push || echo "Nothing to push"
