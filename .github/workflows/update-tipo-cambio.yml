name: Actualizar Tipo de Cambio

on:
  schedule:
    - cron: '0 * * * *'
  workflow_dispatch:
  push:
    branches: [ main ]

permissions:
  contents: write

jobs:
  update-rates:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        pip install requests beautifulsoup4
    
    - name: Obtener tipo de cambio con ScraperAPI
      run: |
        cat > scraper.py << 'ENDOFSCRIPT'
        import requests
        from bs4 import BeautifulSoup
        import json
        import re
        from datetime import datetime
        import urllib3
        urllib3.disable_warnings()
        
        def get_sunat_scraperapi():
            """Obtener SUNAT - Simplemente usar SBS que ya funciona"""
            try:
                print("Obteniendo SUNAT (usando valores de SBS)...")
                
                # Como SUNAT = SBS del día anterior, y SBS ya funciona perfectamente,
                # simplemente usamos los mismos valores de SBS para SUNAT
                
                sbs_result = get_sbs_scraperapi()
                
                if not sbs_result.get('error'):
                    print(f"SUNAT usando valores de SBS: {sbs_result['compra']}/{sbs_result['venta']}")
                    return {
                        "compra": sbs_result['compra'],
                        "venta": sbs_result['venta'],
                        "fecha": datetime.now().strftime("%d/%m/%Y"),
                        "fuente": "sbs_data"
                    }
                    
            except Exception as e:
                print(f"Error: {e}")
            
            return {"error": True, "message": "No se pudo obtener de SUNAT"}
        
        def get_sbs_scraperapi():
            """Obtener SBS - Solo método directo sin ScraperAPI"""
            try:
                print("\nObteniendo SBS...")
                
                # Solo método directo, sin ScraperAPI
                response = requests.get(
                    'https://www.sbs.gob.pe/app/pp/sistip_portal/paginas/publicacion/tipocambiopromedio.aspx',
                    headers={'User-Agent': 'Mozilla/5.0'},
                    verify=False,
                    timeout=15
                )
                
                if response.status_code == 200:
                    html = response.text
                    
                    # Buscar valores 3.XXX
                    valores = re.findall(r'3\.\d{3}', html)
                    
                    if valores:
                        valores_float = [float(v) for v in valores if 3.4 <= float(v) <= 3.8]
                        valores_unicos = list(dict.fromkeys(valores_float))
                        
                        if valores_unicos:
                            compra = valores_unicos[0] if len(valores_unicos) > 0 else 0
                            venta = valores_unicos[1] if len(valores_unicos) > 1 else compra
                            
                            print(f"SBS: {compra}/{venta}")
                            return {
                                "compra": compra,
                                "venta": venta,
                                "fecha": datetime.now().strftime("%d/%m/%Y"),
                                "fuente": "direct"
                            }
                        
            except Exception as e:
                print(f"Error SBS: {e}")
            
            return {"error": True, "message": "No se pudo obtener de SBS"}
        
        # Ejecutar
        print("=" * 60)
        print("OBTENIENDO TIPO DE CAMBIO CON SCRAPERAPI")
        print("=" * 60)
        
        sunat_data = get_sunat_scraperapi()
        sbs_data = get_sbs_scraperapi()
        
        result = {
            "sunat": sunat_data,
            "sbs": sbs_data,
            "ultima_actualizacion": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        with open('tipo-cambio.json', 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        
        print("\n" + "=" * 60)
        print("RESULTADO FINAL:")
        print(f"SUNAT: {sunat_data}")
        print(f"SBS: {sbs_data}")
        print("=" * 60)
        ENDOFSCRIPT
        
        python scraper.py
    
    - name: Mostrar JSON
      run: cat tipo-cambio.json
    
    - name: Commit
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add tipo-cambio.json
        git commit -m "TC via ScraperAPI - $(date +'%d/%m/%Y %H:%M')" || echo "No changes"
        git push || echo "Nothing to push"
